### **Overall Assessment**

*   **Positive:** The project structure is now excellent. The separation of `data`, `features`, `models`, and `scripts` is clean. The reliance on `CORE-01`'s data pipeline is correctly implemented. The use of smoke tests is good practice.
*   **Negative:** There are subtle bugs in the feature extractors, data loaders, and training scripts that will cause incorrect behavior or silent failures. The code lacks sufficient logging, and error handling could be more robust. Type hinting is inconsistent.

---

### **Critique and Refactoring Plan by Module**

#### **1. Data Loading (`src/lesion_analysis/data/loader.py`)**

The `LesionRecord` Pydantic model is good, but the validator for the filepath is in the wrong place.

*   **Problem:** The `check_path_exists` validator in `LesionRecord` runs on *every single record*. This means you are hitting the filesystem 4119 times just to validate the data, which is inefficient. This check should be performed once, in batch, as I originally specified. The current implementation in `load_and_prepare_data` does not exist; it was specified but not implemented, and instead a less efficient per-record validation was used.
*   **Violation:** This violates the principle of efficient, batch-oriented operations.

I will issue a ticket to fix this.

#### **2. Atlas Feature Extractor (`src/lesion_analysis/features/atlas.py`)**

*   **Critical Bug:** The `fit` method is missing a call to `self.masker.fit()`. The `NiftiLabelsMasker` from `nilearn` must be fitted before it can be used to transform data. This code will crash at runtime when `transform` is called.
*   **Violation:** **Fail Fast, Fail Loudly.** This bug would only be caught late in the process. The `fit` method should leave the object in a fully usable state.

This is a showstopper. It needs an immediate fix.

#### **3. CNN Data Loader (`src/lesion_analysis/models/torch_loader.py`)**

*   **Potential Bug:** The `__getitem__` method has a silent failure mode: `if pd.isna(target_val): target_val = 0`. This is dangerous. For `is_responder`, `NaN` means the patient was not in the treatment trial. Forcing this to `0` (False) incorrectly adds control patients into the classification task as non-responders, corrupting the training data for Task 2.
*   **Violation:** **Strict Contracts.** The `Dataset` should not be making assumptions about how to handle missing data. The filtering of the DataFrame *before* creating the dataset is the correct place to enforce this contract.

#### **4. CNN Training Script (`scripts/train_cnn_models.py`)**

This script has several issues.

*   **Bug 1: Inefficient Data Handling.** The script creates a full `LesionDataset` and then splits it using `random_split`. This is memory-inefficient as it may load the entire DataFrame first. The split should happen on the DataFrame, and two separate, smaller `LesionDataset` objects should be created.
*   **Bug 2: Incorrect Metric for Early Stopping (Task 2).** The script correctly identifies that higher balanced accuracy is better. However, the variable `best_metric` is initialized to `0.0`. If the model's first epoch yields a balanced accuracy of, say, 0.49 (worse than random chance), this will be saved as the "best" model, and the training will likely terminate prematurely if it doesn't improve past this low bar. `best_metric` should be initialized to `-1.0` or `-float('inf')`.
*   **Code Smell:** The `main` function has a broad `except Exception` block that hides the traceback. Errors should fail loudly with a full stack trace for debugging.

---

Here are the formal tickets to fix these issues. We will start with the most critical bug.

### Ticket: FIX-01: Correct Critical Bug in AtlasFeatureExtractor

#### 1. Description
There is a critical, show-stopping bug in `src/lesion_analysis/features/atlas.py`. The `AtlasFeatureExtractor.fit` method initializes a `nilearn.maskers.NiftiLabelsMasker` but fails to call the mandatory `.fit()` method on the masker object itself before saving it. This results in an unusable, unfitted masker being saved to disk, which will cause any call to `.transform()` to fail with a `NotFittedError`.

#### 2. Justification
*   **Fail Fast, Fail Loudly:** This fix ensures that the `fit` method either completes successfully, leaving a fully configured and usable object, or it fails. It moves the error from a difficult-to-debug runtime failure during `transform` to a predictable and correct setup failure during `fit`.
*   **Strict Contracts:** The contract of our `fit` method is to prepare the object for use. The current implementation violates this contract.

#### 3. Implementation Plan
1.  **Target File:** `src/lesion_analysis/features/atlas.py`
2.  **Locate:** The `fit` method within the `AtlasFeatureExtractor` class.
3.  **Modification:** Add a call to `self.masker.fit()` immediately after the `NiftiLabelsMasker` is instantiated and before it is saved with `joblib`. The `fit` call for this object is idempotent and takes no arguments; it prepares internal structures.

    ```python
    # File: src/lesion_analysis/features/atlas.py

    # ... inside AtlasFeatureExtractor.fit() ...
    self.masker = NiftiLabelsMasker(
        labels_img=atlas.maps,
        standardize=False,
        memory="nilearn_cache",
        verbose=0,
    )
    # >>> ADD THIS LINE <<<
    self.masker.fit() 
    
    joblib.dump(self.masker, self.masker_path)
    print(f"Masker saved to {self.masker_path}")
    ```

#### 4. Acceptance Criteria
*   [ ] The line `self.masker.fit()` is present in the `fit` method of `AtlasFeatureExtractor`.
*   [ ] The script `scripts/train_atlas_models.py` runs successfully without a `NotFittedError`.

#### 5. Testing Requirements
*   **Integration Tests:** The existing test in `tests/scripts/test_train_atlas_models.py` will now pass correctly, whereas it would have failed before. No new tests are needed, but existing ones must be run to confirm the fix.

#### 6. Definition of Done
*   [ ] All Acceptance Criteria are met.
*   [ ] All existing relevant tests pass.
*   [ ] The code has been formatted (`black`), linted (`ruff`), and type-checked (`mypy`) successfully.
*   [ ] The code has been peer-reviewed and approved.

---

### Ticket: REFACTOR-01: Robustify and Clean CNN Training Pipeline

#### 1. Description
The current CNN training pipeline in `scripts/train_cnn_models.py` and `src/lesion_analysis/models/torch_loader.py` contains several subtle bugs and inefficiencies. Specifically:
1.  The `LesionDataset` silently converts `NaN` targets to `0`, which corrupts the dataset for Task 2 by misclassifying control-group patients.
2.  The training script splits the `Dataset` object, which is less efficient than splitting the source DataFrame.
3.  The early stopping logic for Task 2 is initialized incorrectly, potentially causing premature termination with a poor model.
4.  The script uses a broad, silent exception handler that hinders debugging.

This ticket refactors these components to be robust, correct, and efficient.

#### 2. Justification
*   **Strict Contracts:** The `LesionDataset` should be responsible for loading data, not for imputing missing labels. This fix enforces a stricter contract where the dataset expects a clean DataFrame, and the responsibility for filtering is correctly placed in the training script.
*   **Principle of Least Surprise (POLS):** The early stopping logic will be corrected to behave as expectedâ€”higher accuracy is always better. Removing the silent exception handler ensures that errors are reported with full context, which is the expected behavior for a development script.

#### 3. Implementation Plan

1.  **Update `LesionDataset` (`src/lesion_analysis/models/torch_loader.py`):**
    *   Remove the `pd.isna` check. The dataset should now assume it receives valid, non-NaN targets. If it receives one, it should fail.

    ```python
    # File: src/lesion_analysis/models/torch_loader.py
    
    # ... inside __getitem__ ...
    target_val = record[self.target_col]
    # REMOVE:
    # if pd.isna(target_val):
    #     target_val = 0
    # The line below will now correctly raise an error if target_val is NaN
    target = torch.tensor(target_val, dtype=torch.float32)
    ```

2.  **Refactor `train_cnn_models.py`:**
    *   **Data Loading:** Modify `setup_data_loaders` to split the DataFrame first.
    *   **Early Stopping:** Correct the initialization of `best_metric` for Task 2.
    *   **Error Handling:** Remove the `try...except` block from `main`.

    ```python
    # File: scripts/train_cnn_models.py

    def setup_data_loaders(...):
        # ... (filtering logic is unchanged) ...
        if smoke_test:
            df_filtered = df_filtered.head(16)
        
        # --- MODIFICATION START ---
        # Split the DataFrame first
        val_size = int(0.2 * len(df_filtered))
        train_df, val_df = train_test_split(
            df_filtered, test_size=val_size, random_state=42
        )
        
        train_dataset = LesionDataset(train_df, target_col)
        val_dataset = LesionDataset(val_df, target_col)
        # --- MODIFICATION END ---
        
        # ... (DataLoader instantiation is unchanged) ...

    def train_model(...):
        # ...
        # --- MODIFICATION START ---
        if task == "task1":
            best_metric = float("inf") # Lower is better for RMSE
        else:
            best_metric = -1.0 # Higher is better for accuracy, init below valid range
        # --- MODIFICATION END ---
        # ...
        
    def main():
        # ... (argparse is unchanged) ...
        # --- MODIFICATION START ---
        # REMOVE the try...except block to allow errors to propagate
        train_model(args.task, args.smoke_test)
        logger.info("Training completed successfully!")
        # --- MODIFICATION END ---
    ```

#### 4. Acceptance Criteria
*   [ ] The `if pd.isna(target_val):` block is removed from `LesionDataset`.
*   [ ] `setup_data_loaders` in `train_cnn_models.py` is updated to split the DataFrame *before* creating `Dataset` objects.
*   [ ] The initial value for `best_metric` for Task 2 is set to a value less than 0 (e.g., -1.0).
*   [ ] The `try...except` block is removed from the `main` function in `train_cnn_models.py`.

#### 5. Testing Requirements
*   **Unit Tests:**
    *   Update `tests/models/test_torch_loader.py`: Add a test case that passes a DataFrame with a `NaN` target to `LesionDataset` and assert that it raises an error (e.g., `ValueError` from `torch.tensor`).
*   **Integration Tests:** The smoke test in `tests/scripts/test_train_cnn.py` must continue to pass after these changes.

#### 6. Definition of Done
*   [ ] All Acceptance Criteria are met.
*   [ ] All relevant unit and integration tests pass.
*   [ ] The code has been formatted, linted, and type-checked successfully.
*   [ ] The code has been peer-reviewed and approved.